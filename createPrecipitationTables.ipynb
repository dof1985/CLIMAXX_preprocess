{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa3e939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "import geopandas as gpd\n",
    "from glob import glob\n",
    "from rasterstats import zonal_stats\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from shapely.geometry import mapping\n",
    "import rioxarray as rxr\n",
    "\n",
    "#set up the main function to process the data\n",
    "def process_variable(nc_var, varfiles, nuts, out_dir):\n",
    "    logger.info(f'Loading {len(varfiles)} {nc_var} files...')\n",
    "    \n",
    "    #open the file\n",
    "    ds = xr.open_mfdataset(varfiles)\n",
    "    logger.info(f'Resampling {nc_var} by month...')\n",
    "    #resample the file to the monthly average\n",
    "    ds = ds.resample(time='M').mean()\n",
    "    \n",
    "    #check if the file contains crs data\n",
    "    #in case not, add it\n",
    "    if ds.rio.crs is None:\n",
    "        ds.rio.write_crs(4326, inplace=True)\n",
    "\n",
    "    #clip the data to the NUTS shapefile    \n",
    "    ds_c = ds.rio.clip(nuts.geometry.apply(mapping), nuts.crs, all_touched = True)\n",
    "    \n",
    "    #select the time format, the lon and the lat\n",
    "    time_var, lat_var, lon_var = 'time', 'lat', 'lon'\n",
    "    time_format = \"%Y-%m-%dT%H:%M:%S.%f000\"\n",
    "    \n",
    "    lats, lons = ds_c[lat_var].values, ds_c[lon_var].values\n",
    "    #create an output table with the NUTS data\n",
    "    output_tbl = pd.DataFrame(nuts)\n",
    "    \n",
    "    for t, time_step in enumerate(ds_c[time_var].values):\n",
    "        # for each time step, do the following\n",
    "        \n",
    "        data = ds_c[nc_var][t, :, :].values\n",
    "        datetime_step = datetime.strptime(str(time_step), time_format)\n",
    "        date = datetime_step.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # save the file as a tif\n",
    "        filename = f'{datetime_step:%Y-%m}_{nc_var}.tif'\n",
    "        filename = os.path.join(out_dir, filename)\n",
    "        \n",
    "        #create a raster files for each time step\n",
    "        save_raster(filename, data, lons, lats)\n",
    "        \n",
    "        #perform zonal statistic\n",
    "        with rasterio.open(filename) as src:\n",
    "            affine = src.transform\n",
    "            array = src.read(1)\n",
    "            \n",
    "            ds_zonal_stats = calculate_zonal_stats(nuts, array, affine)\n",
    "            output_tbl[date] = ds_zonal_stats\n",
    "            \n",
    "            if t == 0:\n",
    "                output_tbl = output_tbl.loc[:,['NUTS_ID', date]]\n",
    "\n",
    "    return output_tbl\n",
    "\n",
    "# Create a raster file using rasterio\n",
    "def save_raster(filename, data, lons, lats):\n",
    "    with rasterio.open(\n",
    "        filename,\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=data.shape[0],\n",
    "        width=data.shape[1],\n",
    "        count=1,\n",
    "        dtype=data.dtype,\n",
    "        crs='epsg:4326',\n",
    "        transform=rasterio.transform.from_bounds(lons.min(), lats.min(), lons.max(), lats.max(), data.shape[1], data.shape[0])\n",
    "    ) as dst:\n",
    "        dst.write(data, 1)\n",
    "\n",
    "#perform  zonal statistic\n",
    "def calculate_zonal_stats(nuts, array, affine):\n",
    "    ds_zonal_stats = zonal_stats(nuts, array, affine=affine, stats=['sum'], all_touched = True)\n",
    "    return [i['sum'] for i in ds_zonal_stats]\n",
    "\n",
    "workflow_folder = 'C:/Users/artuso/Documents/CLIMAXX/preprocessing/New-folder'\n",
    "# debug if folder does not exist - issue an error to check path\n",
    "\n",
    "nc_directory = \"P:/watxene/ISIMIP/ISIMIP3a/InputData/climate/obsclim_updated/GSWP3-W5E5\"\n",
    "\n",
    "# create outputs folder\n",
    "if not os.path.exists(os.path.join(workflow_folder, 'data')):\n",
    "    os.makedirs(os.path.join(workflow_folder, 'data'))\n",
    "out_dir = 'C:/Users/artuso/Documents/CLIMAXX/preprocessing/New-folder/data2'\n",
    "nc_vars = ['pr']\n",
    "\n",
    "os.chdir(nc_directory)\n",
    "ncs = glob('*.nc')\n",
    "\n",
    "logger.info(f'Found {len(ncs)} files.')\n",
    "\n",
    "# select polygons if needed (e.g. 3 regions in Italy)\n",
    "#regions = ['ITF1', 'ITF2', 'ITF3']\n",
    "shapefile = os.path.join(workflow_folder, \"NUTS_RG_20M_2021_4326.shp\")\n",
    "nuts = gpd.read_file(shapefile)\n",
    "#filter the NUTS shapefile to the region of interest\n",
    "#nuts = nuts.loc[nuts['NUTS_ID'].isin(regions)]\n",
    "\n",
    "#set up the output file\n",
    "output_tbl = pd.DataFrame(nuts)\n",
    "#drop the columns in excess\n",
    "output_tbl = output_tbl.drop(['geometry'], axis = 1)\n",
    "output_tbl = output_tbl.loc[:,['NUTS_ID']]\n",
    "\n",
    "\n",
    "for nc_var in nc_vars:\n",
    "    # For every nc_var contained in the list nc_vars - do the following:\n",
    "    #if does not work install dependencies netcdf4, h5netcdf and dask\n",
    "\n",
    "    # specify the files format\n",
    "    nc_file_pattern = f'gswp3-w5e5_obsclim_{nc_var}_global_daily_'\n",
    "\n",
    "    # select each of the files that correspond with the format specified\n",
    "    varfiles = [f for f in ncs if nc_file_pattern in f]\n",
    "    \n",
    "    # process the data\n",
    "    result_tbl = process_variable(nc_var, varfiles, nuts, out_dir)\n",
    "    \n",
    "    # merge the results in the output table\n",
    "    output_tbl = pd.merge(output_tbl, result_tbl, on='NUTS_ID')\n",
    "\n",
    "# output_tbl_T = output_tbl.set_index('NUTS_ID').transpose()\n",
    "# function to transpose the dataframe to the required format (columns NUTS_ID, rows YYYY-MM-D)\n",
    "def transpose_dataframe(gdf, agg_field='NUTS_ID'):\n",
    "    df = pd.DataFrame(gdf)\n",
    "        \n",
    "    df.rename(columns={agg_field: 'timing'}, inplace=True)\n",
    "    \n",
    "    df = df.T\n",
    "    new_header = df.iloc[0] \n",
    "    df = df[1:]\n",
    "    df.columns = new_header \n",
    "    \n",
    "    return df\n",
    "\n",
    "output_tbl_T = transpose_dataframe (output_tbl)\n",
    "#save the table as a *csv file\n",
    "output_tbl_T.to_csv(os.path.join(out_dir, 'precip_table.csv'), index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
